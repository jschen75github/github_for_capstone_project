{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Clustering of the Neighborhoods in Houston City, Texas"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Section 1: Data collection and data loading into notebook"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### a) Population data of Houston city, TX (1850 - 2010)"
        },
        {
            "cell_type": "code",
            "execution_count": 197,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>population</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1850</td>\n      <td>2396</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1860</td>\n      <td>4845</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1870</td>\n      <td>9382</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1880</td>\n      <td>16513</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1890</td>\n      <td>27557</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   year  population\n0  1850        2396\n1  1860        4845\n2  1870        9382\n3  1880       16513\n4  1890       27557"
                    },
                    "execution_count": 197,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "import pandas as pd\ndf_ph = pd.read_csv('population_houston_city.csv')\ndf_ph.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### b) List of Houston neighborhoods with lattitude and longitude"
        },
        {
            "cell_type": "code",
            "execution_count": 198,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HoustonNeighborhoods</th>\n      <th>Index</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9_Addicks_Park_Ten</td>\n      <td>9</td>\n      <td>29.813300</td>\n      <td>-95.645500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23_AftonOaks_RiverOaks</td>\n      <td>23</td>\n      <td>29.749994</td>\n      <td>-95.433234</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25_Alief</td>\n      <td>25</td>\n      <td>29.682700</td>\n      <td>-95.593200</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34_Astrodome_Area</td>\n      <td>34</td>\n      <td>29.685045</td>\n      <td>-95.409813</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30_Braeburn</td>\n      <td>30</td>\n      <td>29.682779</td>\n      <td>-95.534980</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "     HoustonNeighborhoods  Index   Latitude  Longitude\n0      9_Addicks_Park_Ten      9  29.813300 -95.645500\n1  23_AftonOaks_RiverOaks     23  29.749994 -95.433234\n2                25_Alief     25  29.682700 -95.593200\n3       34_Astrodome_Area     34  29.685045 -95.409813\n4             30_Braeburn     30  29.682779 -95.534980"
                    },
                    "execution_count": 198,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_n = pd.read_csv('Houston_Neighborhoods.csv')\ndf_n.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### c) Loading of 73 uploaded PDF files into notebook"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### c.1 convert PDF into text using PDFMINER.six"
        },
        {
            "cell_type": "code",
            "execution_count": 199,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting package metadata (current_repodata.json): done\nSolving environment: done\n\n# All requested packages already installed.\n\n"
                }
            ],
            "source": " #!conda install -c conda-forge pdfminer --yes\n!conda install -c conda-forge pdfminer.six --yes"
        },
        {
            "cell_type": "code",
            "execution_count": 200,
            "metadata": {},
            "outputs": [],
            "source": "import io\n\nfrom pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\nfrom pdfminer.converter import TextConverter\nfrom pdfminer.layout import LAParams\nfrom pdfminer.pdfpage import PDFPage\n\n\ndef convert_pdf_to_txt(path):\n    rsrcmgr = PDFResourceManager()\n    retstr = io.StringIO()\n    codec = 'utf-8'\n    laparams = LAParams()\n    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n    fp = open(path, 'rb')\n    interpreter = PDFPageInterpreter(rsrcmgr, device)\n    password = \"\"\n    maxpages = 0\n    caching = True\n    pagenos = set()\n\n    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages,\n                                  password=password,\n                                  caching=caching,\n                                  check_extractable=True):\n        interpreter.process_page(page)\n\n\n\n    fp.close()\n    device.close()\n    text = retstr.getvalue()\n    retstr.close()\n    return text"
        },
        {
            "cell_type": "code",
            "execution_count": 201,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np\nneighbor = df_n.loc[:,'HoustonNeighborhoods'].to_numpy()\nfilename = []\nfor i in range(len(neighbor)):\n    fname = str(neighbor[i]) + '_v2.pdf'\n    filename.append(fname)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Section 2: Data preparation and generation of dataframe"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### a) parse feature data from text"
        },
        {
            "cell_type": "code",
            "execution_count": 202,
            "metadata": {},
            "outputs": [],
            "source": "#function of searching for the various information from the text \n\ndef parse_value(tt):\n    begin = tt.find('characteristics')\n    text = tt[begin:]\n    list1 = []\n#find the Median Household Income for 2015\n    i1 = text.find('Median Household Income')\n    tt_i1 = text[i1:]\n    i2 = tt_i1.find('$')\n    tt_i2 = tt_i1[i2+1:]\n    i3 = tt_i2.find('$')\n    tt_i3 = tt_i2[i3:]\n    i4a = tt_i3.find('$')\n    i4b = tt_i3.find(',')\n    i4c = tt_i3.find(' ')\n    if i4b<i4c:\n        tt_i4 = tt_i3[i4a+1:i4b] + tt_i3[i4b+1:i4c]\n    else:\n        tt_i4 = tt_i3[i4a+1:i4c]\n    if tt_i4 == ' ':\n        Income_Median = float('NaN')\n    else:\n        Income_Median = float(tt_i4)\n    list1.append(Income_Median)\n    #print('Income_Median = ', Income_Median)\n\n#find the Median Housing Value\n    j1 = text.find('Median Housing Value')\n    tt_j1 = text[j1:]\n    j2 = tt_j1.find('$')\n    tt_j2 = tt_j1[j2+1:]\n    j3 = tt_j2.find('$')\n    tt_j3 = tt_j2[j3:]\n    j4a = tt_j3.find('$')\n    j4b = tt_j3.find(',')\n    j4c = tt_j3.find(' ')\n    if j4b<j4c:\n        tt_j4 = tt_j3[j4a+1:j4b] + tt_j3[j4b+1:j4c]\n    else:\n        tt_j4 = tt_j3[j4a+1:j4c]\n    if tt_j4 == '':\n        Housing_Median = float('NaN')\n    else:\n        Housing_Median = float(tt_j4)\n    list1.append(Housing_Median)\n    #print('Housing_Median = ', Housing_Median)\n\n#find the total population and persons per sq. mile\n    k1 = text.find('population')\n    tt_k1 = text[k1:]\n    k2 = tt_k1.find(' ')\n    tt_k2 = tt_k1[k2+1:]\n    k3 = tt_k2.find(' ')\n    tt_k3 = tt_k2[k3+1:]\n    k3b = tt_k3.find(' ')\n    tt_k3b = tt_k3[0:k3b]\n    k3c = tt_k3b.find(',')\n    if k3c == -1:\n        tt_k3b = tt_k3[0:k3b]\n    else:\n        tt_k3b = tt_k3[0:k3c] + tt_k3[k3c+1:k3b]\n    if tt_k3b == '':\n        Population_Total = float('NaN')\n    else:\n        Population_Total = float(tt_k3b)\n        \n    k4 = tt_k2.find('sq. mile')\n    tt_k4 = tt_k2[k4+5:]\n    k5 = tt_k4.find(' ')\n    tt_k5 = tt_k4[k5+1:]\n    k6a = tt_k5.find(' ')\n    tt_k6 = tt_k5[k6a+1:]\n    k6b = tt_k6.find(' ')\n    tt_k6b = tt_k6[0:k6b]\n    k6c = tt_k6b.find(',')\n    if k6c == -1:\n        tt_k6b = tt_k6[0:k6b]\n    else:\n        tt_k6b = tt_k6[0:k6c] + tt_k6[k6c+1:k6b]\n    Psmile_Person = float(tt_k6b)\n    list1.append(Population_Total)\n    list1.append(Psmile_Person)\n    #print('Population_Total = ', Population_Total)\n    #print('Psmile_Person = ', Psmile_Person)\n\n#find all the percentage values into a list\n    l1 = text.find('%')\n    l1end = text.find('Median Housing Value')\n    tt_l1 = text[l1-2:l1end]  \n    for i in range(len(tt_l1)):\n        if tt_l1[i] == '%':\n            list1.append(float(tt_l1[i-2:i]))\n    list2 = list1[0:4]\n    for kk in range(17):\n        index = 4*kk+5\n        list2.append(list1[index])\n    \n    #print(list1)\n    return list2"
        },
        {
            "cell_type": "code",
            "execution_count": 203,
            "metadata": {},
            "outputs": [],
            "source": "neighbor = df_n.loc[:,'HoustonNeighborhoods'].to_numpy()\ndata = {}\nfor i in range(len(filename)):\n    #print('the current file is: ',filename[i])\n    tt = convert_pdf_to_txt(filename[i])\n    data[neighbor[i]] = parse_value(tt)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### b) generate and combine datafame"
        },
        {
            "cell_type": "code",
            "execution_count": 204,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HoustonNeighborhoods</th>\n      <th>Index</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Income_Median</th>\n      <th>Housing_Median</th>\n      <th>Population_Total</th>\n      <th>Psmile_Person</th>\n      <th>Age%_Under5</th>\n      <th>Age%_5_17</th>\n      <th>Age%_18_64</th>\n      <th>Age%_65up</th>\n      <th>Non_Hispanic%_W</th>\n      <th>Non_Hispanic%_B</th>\n      <th>Hispanic%</th>\n      <th>Non_Hispanic%_A</th>\n      <th>Nin_Hispanic%_O</th>\n      <th>Income%_U25k</th>\n      <th>Income%_U50k</th>\n      <th>Income%_U100k</th>\n      <th>Income%_100kup</th>\n      <th>No_Diploma%</th>\n      <th>High_School%</th>\n      <th>College%</th>\n      <th>Bachelor_Or_Higher%</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9_Addicks_Park_Ten</td>\n      <td>9</td>\n      <td>29.813300</td>\n      <td>-95.645500</td>\n      <td>80584.0</td>\n      <td>168155.0</td>\n      <td>19683.0</td>\n      <td>840.0</td>\n      <td>5.0</td>\n      <td>17.0</td>\n      <td>71.0</td>\n      <td>7.0</td>\n      <td>41.0</td>\n      <td>15.0</td>\n      <td>32.0</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>11.0</td>\n      <td>24.0</td>\n      <td>33.0</td>\n      <td>32.0</td>\n      <td>9.0</td>\n      <td>19.0</td>\n      <td>27.0</td>\n      <td>39.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23_AftonOaks_RiverOaks</td>\n      <td>23</td>\n      <td>29.749994</td>\n      <td>-95.433234</td>\n      <td>95682.0</td>\n      <td>499169.0</td>\n      <td>14518.0</td>\n      <td>4021.0</td>\n      <td>5.0</td>\n      <td>14.0</td>\n      <td>61.0</td>\n      <td>20.0</td>\n      <td>77.0</td>\n      <td>4.0</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>10.0</td>\n      <td>23.0</td>\n      <td>58.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>19.0</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25_Alief</td>\n      <td>25</td>\n      <td>29.682700</td>\n      <td>-95.593200</td>\n      <td>41833.0</td>\n      <td>90655.0</td>\n      <td>106657.0</td>\n      <td>7544.0</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>65.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>22.0</td>\n      <td>49.0</td>\n      <td>19.0</td>\n      <td>1.0</td>\n      <td>32.0</td>\n      <td>33.0</td>\n      <td>25.0</td>\n      <td>9.0</td>\n      <td>35.0</td>\n      <td>26.0</td>\n      <td>24.0</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34_Astrodome_Area</td>\n      <td>34</td>\n      <td>29.685045</td>\n      <td>-95.409813</td>\n      <td>46284.0</td>\n      <td>102268.0</td>\n      <td>18223.0</td>\n      <td>4846.0</td>\n      <td>5.0</td>\n      <td>6.0</td>\n      <td>84.0</td>\n      <td>5.0</td>\n      <td>34.0</td>\n      <td>22.0</td>\n      <td>10.0</td>\n      <td>31.0</td>\n      <td>3.0</td>\n      <td>26.0</td>\n      <td>26.0</td>\n      <td>32.0</td>\n      <td>15.0</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>20.0</td>\n      <td>72.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30_Braeburn</td>\n      <td>30</td>\n      <td>29.682779</td>\n      <td>-95.534980</td>\n      <td>42958.0</td>\n      <td>116547.0</td>\n      <td>18843.0</td>\n      <td>4711.0</td>\n      <td>8.0</td>\n      <td>18.0</td>\n      <td>63.0</td>\n      <td>10.0</td>\n      <td>24.0</td>\n      <td>16.0</td>\n      <td>55.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>41.0</td>\n      <td>26.0</td>\n      <td>22.0</td>\n      <td>11.0</td>\n      <td>28.0</td>\n      <td>30.0</td>\n      <td>22.0</td>\n      <td>20.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "     HoustonNeighborhoods  Index   Latitude  Longitude  Income_Median  \\\n0      9_Addicks_Park_Ten      9  29.813300 -95.645500        80584.0   \n1  23_AftonOaks_RiverOaks     23  29.749994 -95.433234        95682.0   \n2                25_Alief     25  29.682700 -95.593200        41833.0   \n3       34_Astrodome_Area     34  29.685045 -95.409813        46284.0   \n4             30_Braeburn     30  29.682779 -95.534980        42958.0   \n\n   Housing_Median  Population_Total  Psmile_Person  Age%_Under5  Age%_5_17  \\\n0        168155.0           19683.0          840.0          5.0       17.0   \n1        499169.0           14518.0         4021.0          5.0       14.0   \n2         90655.0          106657.0         7544.0          7.0       20.0   \n3        102268.0           18223.0         4846.0          5.0        6.0   \n4        116547.0           18843.0         4711.0          8.0       18.0   \n\n   Age%_18_64  Age%_65up  Non_Hispanic%_W  Non_Hispanic%_B  Hispanic%  \\\n0        71.0        7.0             41.0             15.0       32.0   \n1        61.0       20.0             77.0              4.0       10.0   \n2        65.0        8.0              9.0             22.0       49.0   \n3        84.0        5.0             34.0             22.0       10.0   \n4        63.0       10.0             24.0             16.0       55.0   \n\n   Non_Hispanic%_A  Nin_Hispanic%_O  Income%_U25k  Income%_U50k  \\\n0             12.0              1.0          11.0          24.0   \n1              7.0              2.0           9.0          10.0   \n2             19.0              1.0          32.0          33.0   \n3             31.0              3.0          26.0          26.0   \n4              5.0              0.0          41.0          26.0   \n\n   Income%_U100k  Income%_100kup  No_Diploma%  High_School%  College%  \\\n0           33.0            32.0          9.0          19.0      27.0   \n1           23.0            58.0          3.0           4.0      19.0   \n2           25.0             9.0         35.0          26.0      24.0   \n3           32.0            15.0          2.0           7.0      20.0   \n4           22.0            11.0         28.0          30.0      22.0   \n\n   Bachelor_Or_Higher%  \n0                 39.0  \n1                 74.0  \n2                 15.0  \n3                 72.0  \n4                 20.0  "
                    },
                    "execution_count": 204,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_data = pd.DataFrame.from_dict(data, orient='index',\n                                 columns=['Income_Median', 'Housing_Median', 'Population_Total',\n                                          'Psmile_Person', 'Age%_Under5', 'Age%_5_17','Age%_18_64',\n                                          'Age%_65up', 'Non_Hispanic%_W', 'Non_Hispanic%_B',\n                                          'Hispanic%', 'Non_Hispanic%_A', 'Nin_Hispanic%_O',\n                                          'Income%_U25k', 'Income%_U50k', 'Income%_U100k',\n                                          'Income%_100kup', 'No_Diploma%', 'High_School%',\n                                          'College%', 'Bachelor_Or_Higher%']\n                                )\n\ndf_data['Index'] = df_n['Index'].to_numpy()\ndft = pd.merge(df_n, df_data, on='Index')\ndft.head()"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}